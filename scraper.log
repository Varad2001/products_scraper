urllib3.connectionpool:DEBUG:2022-10-03 20:06:25,981:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 20:06:26,738:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 20:06:26,917:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 20:06:27,274:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 369, in connect
    self._tunnel()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 920, in _tunnel
    (version, code, message) = response._read_status()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
urllib3.connectionpool:DEBUG:2022-10-03 20:06:27,305:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 20:06:31,929:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 20:06:31,939:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 20:06:36,432:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /creality-ender-3-v2-black/p/288-00DY-00001 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 20:06:36,436:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 20:06:37,620:https://www.newegg.com:443 "GET /creality-ender-3-v2-black/p/288-00DY-00001 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 20:06:39,963:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 20:06:40,429:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 20:06:40,588:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 20:06:40,967:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 369, in connect
    self._tunnel()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 920, in _tunnel
    (version, code, message) = response._read_status()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
urllib3.connectionpool:DEBUG:2022-10-03 20:06:40,970:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 20:06:45,519:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 20:06:45,524:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 20:06:49,935:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 20:06:49,938:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 20:06:51,106:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 20:12:26,472:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 20:12:27,270:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 20:12:27,439:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 20:12:28,897:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:48:09,323:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 22:48:09,956:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:48:10,135:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 22:49:11,275:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 369, in connect
    self._tunnel()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 924, in _tunnel
    raise OSError(f"Tunnel connection failed: {code} {message.strip()}")
OSError: Tunnel connection failed: 503 Service Unavailable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable')))
urllib3.connectionpool:DEBUG:2022-10-03 22:49:11,304:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 22:49:12,200:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:50:35,221:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 22:50:35,793:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:50:35,948:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 22:50:39,486:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 369, in connect
    self._tunnel()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 920, in _tunnel
    (version, code, message) = response._read_status()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
urllib3.connectionpool:DEBUG:2022-10-03 22:50:39,590:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 22:50:41,219:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 67237
urllib3.connectionpool:DEBUG:2022-10-03 22:51:30,000:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 22:51:30,646:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:51:30,804:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 22:51:39,929:https://www.newegg.com:443 "GET /todays-deals?cm_sp=Head_Navigation-_-Under_Search_Bar-_-Today%27s+Best+Deals&icid=720202 HTTP/1.1" 200 62132
urllib3.connectionpool:DEBUG:2022-10-03 22:52:23,089:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 22:52:23,739:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:52:23,913:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 22:52:24,689:https://www.newegg.com:443 "GET /todays-deals?cm_sp=Head_Navigation-_-Under_Search_Bar-_-Today%27s+Best+Deals&icid=720202 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:52:39,914:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 22:52:40,403:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:52:40,600:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 22:52:41,010:https://www.newegg.com:443 "GET /todays-deals?cm_sp=Head_Navigation-_-Under_Search_Bar-_-Today%27s+Best+Deals&icid=720202 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:53:41,884:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 22:53:42,467:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:53:42,808:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 22:53:43,536:https://www.newegg.com:443 "GET /todays-deals?cm_sp=Head_Navigation-_-Under_Search_Bar-_-Today%27s+Best+Deals&icid=720202 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:57:30,822:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 22:57:31,482:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:57:31,822:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 22:57:32,593:https://www.newegg.com:443 "GET /todays-deals?cm_sp=Head_Navigation-_-Under_Search_Bar-_-Today%27s+Best+Deals&icid=720202 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:59:48,926:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 22:59:49,565:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 22:59:49,731:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 22:59:50,416:https://www.newegg.com:443 "GET /todays-deals?cm_sp=Head_Navigation-_-Under_Search_Bar-_-Today%27s+Best+Deals&icid=720202 HTTP/1.1" 200 62239
urllib3.connectionpool:DEBUG:2022-10-03 23:00:34,481:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:00:35,089:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:00:35,251:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:00:35,661:https://www.newegg.com:443 "GET /todays-deals?cm_sp=Head_Navigation-_-Under_Search_Bar-_-Today%27s+Best+Deals&icid=720202 HTTP/1.1" 200 62196
urllib3.connectionpool:DEBUG:2022-10-03 23:01:19,968:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:01:20,491:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:01:20,643:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:01:21,569:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:01:46,980:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:01:47,532:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:01:47,700:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:01:49,546:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:12:46,192:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:12:46,748:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:12:46,900:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:13:06,151:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002737A54AA40>, 'Connection to 68.183.230.116 timed out. (connect timeout=None)'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 179, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000002737A54AA40>, 'Connection to 68.183.230.116 timed out. (connect timeout=None)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002737A54AA40>, 'Connection to 68.183.230.116 timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 553, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002737A54AA40>, 'Connection to 68.183.230.116 timed out. (connect timeout=None)'))
urllib3.connectionpool:DEBUG:2022-10-03 23:13:06,179:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:13:10,767:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 23:13:10,777:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:13:13,300:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 369, in connect
    self._tunnel()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 920, in _tunnel
    (version, code, message) = response._read_status()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
urllib3.connectionpool:DEBUG:2022-10-03 23:13:13,309:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:13:22,459:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:13:23,004:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:13:23,521:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:13:23,671:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:13:26,029:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737ACF8D00>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000002737ACF8D00>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737ACF8D00>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737ACF8D00>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
urllib3.connectionpool:DEBUG:2022-10-03 23:13:26,032:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:13:30,548:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 23:13:30,552:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:13:53,637:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:13:54,221:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:13:54,756:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:13:54,936:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:13:57,306:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737A2470A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000002737A2470A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737A2470A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737A2470A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
urllib3.connectionpool:DEBUG:2022-10-03 23:13:57,310:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:14:01,821:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 23:14:01,825:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:14:05,890:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:14:06,568:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:14:07,060:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:14:07,214:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:14:09,570:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737B399750>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000002737B399750>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737B399750>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002737B399750>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
urllib3.connectionpool:DEBUG:2022-10-03 23:14:09,573:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:14:14,122:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 23:14:14,125:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:15:06,145:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:15:06,719:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:15:06,890:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:15:09,242:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002779ED7EBF0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000002779ED7EBF0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002779ED7EBF0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002779ED7EBF0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
urllib3.connectionpool:DEBUG:2022-10-03 23:15:09,268:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:15:13,798:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 23:15:13,810:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:15:16,384:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 369, in connect
    self._tunnel()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 920, in _tunnel
    (version, code, message) = response._read_status()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
urllib3.connectionpool:DEBUG:2022-10-03 23:15:16,411:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:15:20,746:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:15:21,168:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-03 23:15:21,659:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-03 23:15:21,806:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:15:24,142:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002779F5295D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000002779F5295D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002779F5295D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002779F5295D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')))
urllib3.connectionpool:DEBUG:2022-10-03 23:15:24,145:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:15:28,685:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-03 23:15:28,689:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:15:31,205:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 369, in connect
    self._tunnel()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 920, in _tunnel
    (version, code, message) = response._read_status()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)))
urllib3.connectionpool:DEBUG:2022-10-03 23:15:31,208:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-03 23:15:50,882:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002779F529C00>, 'Connection to 222.237.249.172 timed out. (connect timeout=None)'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 179, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000002779F529C00>, 'Connection to 222.237.249.172 timed out. (connect timeout=None)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002779F529C00>, 'Connection to 222.237.249.172 timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 553, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002779F529C00>, 'Connection to 222.237.249.172 timed out. (connect timeout=None)'))
urllib3.connectionpool:DEBUG:2022-10-03 23:15:50,886:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-03 23:15:52,421:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 403 552
urllib3.connectionpool:DEBUG:2022-10-04 10:57:01,075:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 10:57:01,773:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 10:57:01,934:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 10:57:02,819:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:02:00,662:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:02:01,425:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:02:01,579:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:02:02,325:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:03:31,100:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:03:31,636:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:03:31,792:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 12:03:40,431:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 12:03:40,461:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 12:04:01,578:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000014308B73430>, 'Connection to 51.159.207.156 timed out. (connect timeout=None)'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 179, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x0000014308B73430>, 'Connection to 51.159.207.156 timed out. (connect timeout=None)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000014308B73430>, 'Connection to 51.159.207.156 timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 553, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000014308B73430>, 'Connection to 51.159.207.156 timed out. (connect timeout=None)'))
urllib3.connectionpool:DEBUG:2022-10-04 12:04:01,584:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:04:03,232:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:05:38,203:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:05:38,885:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:05:39,050:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 12:05:42,520:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 12:05:42,543:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 12:06:03,576:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025128133400>, 'Connection to 51.159.207.156 timed out. (connect timeout=None)'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 179, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x0000025128133400>, 'Connection to 51.159.207.156 timed out. (connect timeout=None)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025128133400>, 'Connection to 51.159.207.156 timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 553, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025128133400>, 'Connection to 51.159.207.156 timed out. (connect timeout=None)'))
urllib3.connectionpool:DEBUG:2022-10-04 12:06:03,581:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:06:04,935:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:15:31,711:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:15:32,423:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:15:32,579:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:15:33,611:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:02,778:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:03,328:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:03,492:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:04,827:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:05,519:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:06,051:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:06,197:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:06,712:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:07,394:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:07,885:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:08,058:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:08,802:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1&page=1&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:09,544:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:10,026:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:10,173:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:11,104:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1&page=1&page=1&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:11,808:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:12,273:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:12,456:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:13,355:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1&page=1&page=1&page=1&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:19:14,056:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:19:14,517:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:20:29,522:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:20:30,045:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:20:30,199:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:20:30,825:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:20:31,691:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:20:32,158:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:20:32,295:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:20:32,812:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:21:27,950:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:21:28,681:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:21:28,827:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:21:29,530:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:21:30,043:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:21:30,538:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:21:30,686:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:21:31,523:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:27:14,924:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:27:15,598:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:27:15,752:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:27:16,439:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:27:30,656:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:27:31,240:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:27:31,409:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:27:43,092:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 503 1203
urllib3.connectionpool:DEBUG:2022-10-04 12:27:51,567:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:27:52,160:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:27:52,317:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:28:03,884:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 503 1203
urllib3.connectionpool:DEBUG:2022-10-04 12:29:53,676:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:29:54,394:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:29:54,553:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:30:08,270:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 503 1203
urllib3.connectionpool:DEBUG:2022-10-04 12:33:42,920:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:33:43,582:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:33:43,738:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 12:33:48,305:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 12:33:48,331:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:33:49,032:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:33:49,669:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 12:33:50,222:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 12:33:50,375:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 12:33:54,892:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=2 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=2 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 71, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=2 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 12:33:54,896:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 12:33:55,579:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:15:27,311:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 15:15:28,343:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:15:28,584:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 15:15:29,764:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:15:30,506:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 15:15:31,274:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:15:31,444:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 15:15:32,306:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:15:32,968:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 15:15:33,530:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:15:33,707:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 15:15:35,073:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:15,911:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:16,466:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:16,667:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:17,783:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:18,514:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:19,258:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:19,430:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:20,161:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AEFY5sTMk3Z4ZRYMmgxKXMZnGREWYV07tNThsyh91Lec&qid=1664860424&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:20,865:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:21,350:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:21,580:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:22,794:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 66284
urllib3.connectionpool:DEBUG:2022-10-04 15:16:23,142:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:23,654:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:23,873:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:24,890:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:25,274:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:25,788:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 15:16:26,105:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 15:16:27,195:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 39366
urllib3.connectionpool:DEBUG:2022-10-04 16:17:26,146:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:26,866:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:27,059:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:28,046:https://www.amazon.com:443 "GET /b/ref=s9_acss_bw_cg_AASPHMNY_1c1_w?node=3236453011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-5&pf_rd_r=VZ6JEFNGJXWW4H6FJM1P&pf_rd_t=101&pf_rd_p=a04e434e-03ed-4878-87c6-82c2e9bb5ce3&pf_rd_i=172563&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:28,800:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:29,321:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:29,518:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:30,218:https://www.amazon.com:443 "GET /b/ref=s9_acss_bw_cg_AASPHMNY_1c1_w?node=3236453011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-5&pf_rd_r=VZ6JEFNGJXWW4H6FJM1P&pf_rd_t=101&pf_rd_p=a04e434e-03ed-4878-87c6-82c2e9bb5ce3&pf_rd_i=172563&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:31,037:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:31,563:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:31,747:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:33,963:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:34,177:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:34,677:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:34,840:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:36,499:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:37,026:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:37,562:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:17:37,721:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:17:38,776:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 39394
urllib3.connectionpool:DEBUG:2022-10-04 16:25:13,925:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:14,631:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:14,806:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:16,326:https://www.amazon.com:443 "GET /b/ref=s9_acss_bw_cg_AASPHMNY_1c1_w?node=3236453011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-5&pf_rd_r=VZ6JEFNGJXWW4H6FJM1P&pf_rd_t=101&pf_rd_p=a04e434e-03ed-4878-87c6-82c2e9bb5ce3&pf_rd_i=172563&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:17,097:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:17,582:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:17,761:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:18,553:https://www.amazon.com:443 "GET /b/ref=s9_acss_bw_cg_AASPHMNY_1c1_w?node=3236453011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-5&pf_rd_r=VZ6JEFNGJXWW4H6FJM1P&pf_rd_t=101&pf_rd_p=a04e434e-03ed-4878-87c6-82c2e9bb5ce3&pf_rd_i=172563&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:19,333:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:19,847:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:20,025:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:23,253:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:23,688:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:24,205:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:24,382:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:26,412:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:26,976:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:27,494:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 16:25:27,700:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 16:25:28,561:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 39416
urllib3.connectionpool:DEBUG:2022-10-04 17:19:39,229:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:39,997:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:40,228:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:41,649:https://www.amazon.com:443 "GET /b/ref=s9_acss_bw_cg_AASPHMNY_1c1_w?node=3236453011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-5&pf_rd_r=VZ6JEFNGJXWW4H6FJM1P&pf_rd_t=101&pf_rd_p=a04e434e-03ed-4878-87c6-82c2e9bb5ce3&pf_rd_i=172563&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:42,413:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:42,966:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:43,155:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:44,064:https://www.amazon.com:443 "GET /b/ref=s9_acss_bw_cg_AASPHMNY_1c1_w?node=3236453011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-5&pf_rd_r=VZ6JEFNGJXWW4H6FJM1P&pf_rd_t=101&pf_rd_p=a04e434e-03ed-4878-87c6-82c2e9bb5ce3&pf_rd_i=172563&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:44,859:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:45,391:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:45,587:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:47,455:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:47,628:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:48,417:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:48,593:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:49,986:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:50,435:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:50,934:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:51,104:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:51,966:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 39405
urllib3.connectionpool:DEBUG:2022-10-04 17:19:52,383:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:52,891:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:19:53,076:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:19:54,068:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35693
urllib3.connectionpool:DEBUG:2022-10-04 17:20:03,124:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:03,658:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:20:03,908:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:04,494:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 21892
urllib3.connectionpool:DEBUG:2022-10-04 17:20:13,467:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:14,074:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:20:14,269:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:15,207:https://www.newegg.com:443 "GET /klipsch-1062295/p/0S6-0033-001N6 HTTP/1.1" 200 26244
urllib3.connectionpool:DEBUG:2022-10-04 17:20:24,478:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:25,109:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:20:25,282:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:26,013:https://www.newegg.com:443 "GET /p/0S6-001N-00069 HTTP/1.1" 200 26105
urllib3.connectionpool:DEBUG:2022-10-04 17:20:35,231:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:35,852:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:20:36,023:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:36,763:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23816
urllib3.connectionpool:DEBUG:2022-10-04 17:20:45,762:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:46,406:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:20:46,584:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:47,323:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35722
urllib3.connectionpool:DEBUG:2022-10-04 17:20:56,294:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:56,802:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:20:57,053:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:20:57,579:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 22105
urllib3.connectionpool:DEBUG:2022-10-04 17:21:06,929:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:07,455:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:21:07,635:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:08,495:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24827
urllib3.connectionpool:DEBUG:2022-10-04 17:21:17,678:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:18,212:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:21:18,418:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:19,133:https://www.newegg.com:443 "GET /p/18M-00X2-00012 HTTP/1.1" 200 25399
urllib3.connectionpool:DEBUG:2022-10-04 17:21:28,111:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:28,635:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:21:29,623:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:30,238:https://www.newegg.com:443 "GET /p/0S6-00W1-002H6 HTTP/1.1" 200 23431
urllib3.connectionpool:DEBUG:2022-10-04 17:21:39,207:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:39,846:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:21:40,058:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:40,697:https://www.newegg.com:443 "GET /p/0S6-00W1-002H9 HTTP/1.1" 200 22352
urllib3.connectionpool:DEBUG:2022-10-04 17:21:49,842:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:50,348:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:21:50,499:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:51,196:https://www.newegg.com:443 "GET /p/0S6-00W1-002J0 HTTP/1.1" 200 23525
root:ERROR:2022-10-04 17:21:51,270:'NoneType' object has no attribute 'string'
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 41, in get_details_and_store
    results = get_all_details(url, q, category)
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\newegg.py", line 131, in get_all_details
    results['productPrice'] =  get_price(page)
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\newegg.py", line 103, in get_price
    price = price_tag.strong.string + price_tag.sup.string
AttributeError: 'NoneType' object has no attribute 'string'
urllib3.connectionpool:DEBUG:2022-10-04 17:21:51,311:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:51,859:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:21:52,238:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:21:52,870:https://www.newegg.com:443 "GET /p/0S6-00W1-002H6 HTTP/1.1" 200 21968
urllib3.connectionpool:DEBUG:2022-10-04 17:22:01,790:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:02,403:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:22:02,753:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:04,805:https://www.newegg.com:443 "GET /p/0S6-00W1-002H9 HTTP/1.1" 200 23156
urllib3.connectionpool:DEBUG:2022-10-04 17:22:13,797:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:14,347:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:22:14,524:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:15,334:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 23064
urllib3.connectionpool:DEBUG:2022-10-04 17:22:24,351:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:24,916:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:22:25,141:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:25,893:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 23839
urllib3.connectionpool:DEBUG:2022-10-04 17:22:35,157:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:35,699:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:22:35,923:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:36,695:https://www.newegg.com:443 "GET /fluance-ai81b/p/0S6-004W-000S9 HTTP/1.1" 200 24209
urllib3.connectionpool:DEBUG:2022-10-04 17:22:45,620:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:46,110:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:22:46,278:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:46,894:https://www.newegg.com:443 "GET /fluance-ai81/p/0S6-004W-000T2 HTTP/1.1" 200 25028
urllib3.connectionpool:DEBUG:2022-10-04 17:22:55,833:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:56,373:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:22:56,613:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:22:57,731:https://www.newegg.com:443 "GET /fluance-ai81w/p/0S6-004W-000T3 HTTP/1.1" 200 25048
urllib3.connectionpool:DEBUG:2022-10-04 17:23:06,757:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:07,358:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:23:07,557:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:08,379:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35722
urllib3.connectionpool:DEBUG:2022-10-04 17:23:17,466:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:18,086:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:23:18,263:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:18,852:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 22105
urllib3.connectionpool:DEBUG:2022-10-04 17:23:27,903:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:28,497:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:23:28,679:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:29,320:https://www.newegg.com:443 "GET /fluance-xl8fw/p/0S6-004W-000J2 HTTP/1.1" 200 24891
urllib3.connectionpool:DEBUG:2022-10-04 17:23:38,324:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:38,970:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:23:39,165:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:39,963:https://www.newegg.com:443 "GET /fluance-xl8f/p/0S6-004W-000J5 HTTP/1.1" 200 24499
urllib3.connectionpool:DEBUG:2022-10-04 17:23:49,678:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:50,289:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:23:50,474:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:23:51,514:https://www.newegg.com:443 "GET /fluance-xl8fw/p/0S6-004W-000J2 HTTP/1.1" 200 24060
urllib3.connectionpool:DEBUG:2022-10-04 17:24:00,507:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:01,205:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:24:01,349:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:01,988:https://www.newegg.com:443 "GET /fluance-xl8f/p/0S6-004W-000J5 HTTP/1.1" 200 23622
urllib3.connectionpool:DEBUG:2022-10-04 17:24:11,332:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:11,849:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:24:12,021:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:12,487:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35722
urllib3.connectionpool:DEBUG:2022-10-04 17:24:21,527:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:22,059:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:24:22,333:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:22,717:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 21892
urllib3.connectionpool:DEBUG:2022-10-04 17:24:31,710:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:32,254:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:24:32,410:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:33,178:https://www.newegg.com:443 "GET /klipsch-1062295/p/0S6-0033-001N6 HTTP/1.1" 200 26213
urllib3.connectionpool:DEBUG:2022-10-04 17:24:42,285:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:42,790:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:24:42,962:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:44,361:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24827
urllib3.connectionpool:DEBUG:2022-10-04 17:24:53,523:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:54,422:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:24:54,649:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:24:55,023:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35693
urllib3.connectionpool:DEBUG:2022-10-04 17:25:04,947:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:05,459:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:25:05,617:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:06,165:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 21892
urllib3.connectionpool:DEBUG:2022-10-04 17:25:15,463:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:15,962:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:25:16,139:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:17,286:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23816
urllib3.connectionpool:DEBUG:2022-10-04 17:25:26,388:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:26,916:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:25:27,166:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:27,826:https://www.newegg.com:443 "GET /p/18M-00X2-00012 HTTP/1.1" 200 25399
urllib3.connectionpool:DEBUG:2022-10-04 17:25:36,825:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:37,381:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:25:38,455:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:38,943:https://www.newegg.com:443 "GET /p/0S6-00W1-002H6 HTTP/1.1" 200 23431
urllib3.connectionpool:DEBUG:2022-10-04 17:25:48,024:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:48,549:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:25:48,766:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:49,165:https://www.newegg.com:443 "GET /p/0S6-00W1-002H9 HTTP/1.1" 200 23156
urllib3.connectionpool:DEBUG:2022-10-04 17:25:58,255:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:58,765:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:25:58,959:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:25:59,671:https://www.newegg.com:443 "GET /p/0S6-00W1-002J0 HTTP/1.1" 200 23525
root:ERROR:2022-10-04 17:25:59,739:'NoneType' object has no attribute 'string'
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 41, in get_details_and_store
    results = get_all_details(url, q, category)
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\newegg.py", line 131, in get_all_details
    results['productPrice'] =  get_price(page)
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\newegg.py", line 103, in get_price
    price = price_tag.strong.string + price_tag.sup.string
AttributeError: 'NoneType' object has no attribute 'string'
urllib3.connectionpool:DEBUG:2022-10-04 17:25:59,780:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:00,290:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:26:00,441:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:01,064:https://www.newegg.com:443 "GET /p/0S6-00W1-002H6 HTTP/1.1" 200 23431
urllib3.connectionpool:DEBUG:2022-10-04 17:26:10,025:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:10,587:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:26:10,772:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:11,160:https://www.newegg.com:443 "GET /p/0S6-00W1-002H9 HTTP/1.1" 200 23156
urllib3.connectionpool:DEBUG:2022-10-04 17:26:20,205:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:20,721:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:26:20,910:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:21,537:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21624
urllib3.connectionpool:DEBUG:2022-10-04 17:26:30,550:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:31,072:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:26:31,257:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:31,893:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22649
urllib3.connectionpool:DEBUG:2022-10-04 17:26:41,041:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:41,576:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:26:41,782:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:42,286:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35722
urllib3.connectionpool:DEBUG:2022-10-04 17:26:51,224:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:51,819:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:26:52,009:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:26:52,407:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 21892
urllib3.connectionpool:DEBUG:2022-10-04 17:27:01,593:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:02,080:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:27:02,301:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:02,946:https://www.newegg.com:443 "GET /fluance-ai81b/p/0S6-004W-000S9 HTTP/1.1" 200 25038
urllib3.connectionpool:DEBUG:2022-10-04 17:27:11,898:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:12,551:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:27:12,814:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:13,206:https://www.newegg.com:443 "GET /fluance-ai81/p/0S6-004W-000T2 HTTP/1.1" 200 25028
urllib3.connectionpool:DEBUG:2022-10-04 17:27:22,112:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:22,636:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:27:22,805:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:23,582:https://www.newegg.com:443 "GET /fluance-ai81w/p/0S6-004W-000T3 HTTP/1.1" 200 25048
urllib3.connectionpool:DEBUG:2022-10-04 17:27:32,649:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:33,280:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:27:33,528:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:34,222:https://www.newegg.com:443 "GET /fluance-xl8fw/p/0S6-004W-000J2 HTTP/1.1" 200 24891
urllib3.connectionpool:DEBUG:2022-10-04 17:27:43,156:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:43,648:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:27:43,926:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:44,963:https://www.newegg.com:443 "GET /fluance-xl8f/p/0S6-004W-000J5 HTTP/1.1" 200 24499
urllib3.connectionpool:DEBUG:2022-10-04 17:27:54,727:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:55,304:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:27:55,491:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:27:56,163:https://www.newegg.com:443 "GET /fluance-xl8fw/p/0S6-004W-000J2 HTTP/1.1" 200 24891
urllib3.connectionpool:DEBUG:2022-10-04 17:28:05,238:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 17:28:05,844:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 17:28:06,051:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 17:28:07,118:https://www.newegg.com:443 "GET /fluance-xl8f/p/0S6-004W-000J5 HTTP/1.1" 200 24499
werkzeug:INFO:2022-10-04 19:57:44,808:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-04 19:57:44,808:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-04 19:57:51,389:127.0.0.1 - - [04/Oct/2022 19:57:51] "[33mGET / HTTP/1.1[0m" 404 -
werkzeug:INFO:2022-10-04 19:57:54,801:127.0.0.1 - - [04/Oct/2022 19:57:54] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
werkzeug:INFO:2022-10-04 19:57:56,413:127.0.0.1 - - [04/Oct/2022 19:57:56] "[33mGET / HTTP/1.1[0m" 404 -
werkzeug:INFO:2022-10-04 19:57:56,987:127.0.0.1 - - [04/Oct/2022 19:57:56] "[33mGET / HTTP/1.1[0m" 404 -
werkzeug:INFO:2022-10-04 19:59:07,889:127.0.0.1 - - [04/Oct/2022 19:59:07] "[31m[1mPOST /begin_crawl HTTP/1.1[0m" 405 -
werkzeug:INFO:2022-10-04 19:59:39,260:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-04 19:59:39,260:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-04 19:59:55,185:127.0.0.1 - - [04/Oct/2022 19:59:55] "POST /begin_crawl HTTP/1.1" 200 -
werkzeug:INFO:2022-10-04 20:01:24,795:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-04 20:01:24,795:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-04 20:02:14,489:127.0.0.1 - - [04/Oct/2022 20:02:14] "POST /begin_crawl HTTP/1.1" 200 -
werkzeug:INFO:2022-10-04 20:02:49,201:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-04 20:02:49,202:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-04 20:03:24,440:127.0.0.1 - - [04/Oct/2022 20:03:24] "POST /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-04 20:03:24,461:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:25,199:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:25,369:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:26,916:https://www.amazon.com:443 "GET /b/ref=s9_acss_bw_cg_AASPHMNY_1c1_w?node=3236453011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-5&pf_rd_r=VZ6JEFNGJXWW4H6FJM1P&pf_rd_t=101&pf_rd_p=a04e434e-03ed-4878-87c6-82c2e9bb5ce3&pf_rd_i=172563&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:27,689:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:28,234:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:28,482:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:29,297:https://www.amazon.com:443 "GET /b/ref=s9_acss_bw_cg_AASPHMNY_1c1_w?node=3236453011&pf_rd_m=ATVPDKIKX0DER&pf_rd_s=merchandised-search-5&pf_rd_r=VZ6JEFNGJXWW4H6FJM1P&pf_rd_t=101&pf_rd_p=a04e434e-03ed-4878-87c6-82c2e9bb5ce3&pf_rd_i=172563&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:30,052:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:30,585:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:30,765:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:31,953:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:32,306:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:32,812:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:33,060:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:33,981:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:34,335:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:34,865:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:35,183:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:35,916:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 39021
urllib3.connectionpool:DEBUG:2022-10-04 20:03:36,381:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:36,904:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:37,230:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:38,158:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35688
urllib3.connectionpool:DEBUG:2022-10-04 20:03:47,009:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:47,507:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:47,681:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:48,232:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 21892
urllib3.connectionpool:DEBUG:2022-10-04 20:03:57,003:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:57,511:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:03:57,713:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:03:58,444:https://www.newegg.com:443 "GET /klipsch-1062295/p/0S6-0033-001N6 HTTP/1.1" 200 26244
urllib3.connectionpool:DEBUG:2022-10-04 20:04:07,346:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:07,904:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:04:08,146:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:08,764:https://www.newegg.com:443 "GET /p/0S6-001N-00069 HTTP/1.1" 200 26112
urllib3.connectionpool:DEBUG:2022-10-04 20:04:17,728:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:18,246:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:04:18,413:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:19,539:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23818
urllib3.connectionpool:DEBUG:2022-10-04 20:04:28,480:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:28,956:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:04:29,142:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:29,845:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35688
urllib3.connectionpool:DEBUG:2022-10-04 20:04:38,600:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:39,118:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:04:39,332:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:39,804:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 22105
urllib3.connectionpool:DEBUG:2022-10-04 20:04:48,640:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:49,117:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:04:49,291:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:50,048:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35717
urllib3.connectionpool:DEBUG:2022-10-04 20:04:58,813:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:04:59,408:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:04:59,571:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:00,175:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 22105
urllib3.connectionpool:DEBUG:2022-10-04 20:05:09,097:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:09,585:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:05:09,750:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:10,485:https://www.newegg.com:443 "GET /p/0S6-00W1-002J0 HTTP/1.1" 200 23526
root:ERROR:2022-10-04 20:05:10,540:'NoneType' object has no attribute 'string'
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 41, in get_details_and_store
    results = get_all_details(url, q, category)
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\newegg.py", line 131, in get_all_details
    results['productPrice'] =  get_price(page)
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\newegg.py", line 103, in get_price
    price = price_tag.strong.string + price_tag.sup.string
AttributeError: 'NoneType' object has no attribute 'string'
urllib3.connectionpool:DEBUG:2022-10-04 20:05:10,595:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:11,138:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:05:11,333:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:11,915:https://www.newegg.com:443 "GET /p/0S6-00W1-002H6 HTTP/1.1" 200 23431
urllib3.connectionpool:DEBUG:2022-10-04 20:05:20,649:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:21,139:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:05:21,361:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:21,964:https://www.newegg.com:443 "GET /p/0S6-00W1-002H9 HTTP/1.1" 200 23157
urllib3.connectionpool:DEBUG:2022-10-04 20:05:31,275:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:31,820:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:05:31,979:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:32,961:https://www.newegg.com:443 "GET /p/18M-00X2-00012 HTTP/1.1" 200 25399
urllib3.connectionpool:DEBUG:2022-10-04 20:05:41,767:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:42,256:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:05:42,407:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:42,853:https://www.newegg.com:443 "GET /p/0S6-00W1-002H6 HTTP/1.1" 200 23431
urllib3.connectionpool:DEBUG:2022-10-04 20:05:51,624:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:52,125:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:05:52,364:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:05:53,226:https://www.newegg.com:443 "GET /p/0S6-00W1-002H9 HTTP/1.1" 200 22353
urllib3.connectionpool:DEBUG:2022-10-04 20:06:02,187:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:02,767:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:06:02,920:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:03,916:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21624
urllib3.connectionpool:DEBUG:2022-10-04 20:06:12,679:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:13,195:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:06:13,340:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:14,042:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22650
urllib3.connectionpool:DEBUG:2022-10-04 20:06:22,895:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:23,400:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:06:23,612:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:24,512:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24828
urllib3.connectionpool:DEBUG:2022-10-04 20:06:33,468:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:33,959:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:06:34,130:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:34,773:https://www.newegg.com:443 "GET /fluance-hffw/p/0N6-0174-00010 HTTP/1.1" 200 23561
urllib3.connectionpool:DEBUG:2022-10-04 20:06:43,550:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:44,182:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:06:44,443:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:45,119:https://www.newegg.com:443 "GET /fluance-hff/p/0N6-0174-00011 HTTP/1.1" 200 24367
urllib3.connectionpool:DEBUG:2022-10-04 20:06:54,250:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:54,757:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:06:54,977:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:06:55,574:https://www.newegg.com:443 "GET /fluance-ai81b/p/0S6-004W-000S9 HTTP/1.1" 200 24211
urllib3.connectionpool:DEBUG:2022-10-04 20:07:04,302:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:04,809:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:07:04,956:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:05,859:https://www.newegg.com:443 "GET /fluance-ai81/p/0S6-004W-000T2 HTTP/1.1" 200 24194
urllib3.connectionpool:DEBUG:2022-10-04 20:07:14,626:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:15,230:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:07:15,413:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:16,142:https://www.newegg.com:443 "GET /fluance-ai81w/p/0S6-004W-000T3 HTTP/1.1" 200 24228
urllib3.connectionpool:DEBUG:2022-10-04 20:07:25,941:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:26,508:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:07:26,748:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:27,218:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35688
urllib3.connectionpool:DEBUG:2022-10-04 20:07:36,172:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:36,692:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:07:36,918:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:37,297:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 21892
urllib3.connectionpool:DEBUG:2022-10-04 20:07:46,023:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:46,619:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:07:46,760:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:47,412:https://www.newegg.com:443 "GET /klipsch-1062295/p/0S6-0033-001N6 HTTP/1.1" 200 26212
urllib3.connectionpool:DEBUG:2022-10-04 20:07:56,348:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:56,832:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:07:56,972:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:07:57,304:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23818
urllib3.connectionpool:DEBUG:2022-10-04 20:08:06,074:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:06,574:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:08:06,734:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:07,428:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35688
urllib3.connectionpool:DEBUG:2022-10-04 20:08:16,132:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:16,606:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:08:16,803:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:17,173:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 21892
urllib3.connectionpool:DEBUG:2022-10-04 20:08:26,146:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:26,648:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:08:26,800:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:27,176:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4 HTTP/1.1" 200 35688
urllib3.connectionpool:DEBUG:2022-10-04 20:08:35,956:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:36,428:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:08:36,576:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:37,422:https://www.newegg.com:443 "GET /klipsch-r-625fa-reference/p/12K-00EF-000N4R HTTP/1.1" 200 21892
urllib3.connectionpool:DEBUG:2022-10-04 20:08:46,280:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:46,912:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:08:47,106:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:47,526:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21624
urllib3.connectionpool:DEBUG:2022-10-04 20:08:56,268:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:56,795:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:08:56,943:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:08:57,906:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22650
urllib3.connectionpool:DEBUG:2022-10-04 20:09:06,960:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:07,494:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:09:07,636:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:08,674:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24828
urllib3.connectionpool:DEBUG:2022-10-04 20:09:17,839:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:18,331:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:09:18,534:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:19,368:https://www.newegg.com:443 "GET /p/0S6-00W1-002J0 HTTP/1.1" 200 23444
root:ERROR:2022-10-04 20:09:19,446:'NoneType' object has no attribute 'string'
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 41, in get_details_and_store
    results = get_all_details(url, q, category)
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\newegg.py", line 131, in get_all_details
    results['productPrice'] =  get_price(page)
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\newegg.py", line 103, in get_price
    price = price_tag.strong.string + price_tag.sup.string
AttributeError: 'NoneType' object has no attribute 'string'
urllib3.connectionpool:DEBUG:2022-10-04 20:09:19,489:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:19,977:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:09:20,141:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:20,943:https://www.newegg.com:443 "GET /p/0S6-00W1-002H6 HTTP/1.1" 200 21968
urllib3.connectionpool:DEBUG:2022-10-04 20:09:29,674:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:30,156:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:09:30,317:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:30,801:https://www.newegg.com:443 "GET /p/0S6-00W1-002H9 HTTP/1.1" 200 22353
urllib3.connectionpool:DEBUG:2022-10-04 20:09:39,992:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:40,505:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:09:40,692:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:41,386:https://www.newegg.com:443 "GET /p/18M-00X2-00012 HTTP/1.1" 200 25399
urllib3.connectionpool:DEBUG:2022-10-04 20:09:50,254:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:50,765:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:09:50,913:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:09:51,944:https://www.newegg.com:443 "GET /p/0S6-00W1-002H6 HTTP/1.1" 200 21968
urllib3.connectionpool:DEBUG:2022-10-04 20:10:00,728:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:01,225:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:10:01,414:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:01,798:https://www.newegg.com:443 "GET /p/0S6-00W1-002H9 HTTP/1.1" 200 22353
urllib3.connectionpool:DEBUG:2022-10-04 20:10:10,597:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:11,112:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:10:11,389:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:12,098:https://www.newegg.com:443 "GET /fluance-ai81b/p/0S6-004W-000S9 HTTP/1.1" 200 25039
urllib3.connectionpool:DEBUG:2022-10-04 20:10:20,836:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:21,347:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:10:21,493:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:22,507:https://www.newegg.com:443 "GET /fluance-ai81/p/0S6-004W-000T2 HTTP/1.1" 200 24194
urllib3.connectionpool:DEBUG:2022-10-04 20:10:31,265:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:31,781:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:10:31,966:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:32,623:https://www.newegg.com:443 "GET /fluance-ai81w/p/0S6-004W-000T3 HTTP/1.1" 200 25050
urllib3.connectionpool:DEBUG:2022-10-04 20:10:41,610:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:42,197:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:10:42,340:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:42,999:https://www.newegg.com:443 "GET /fluance-xl8fw/p/0S6-004W-000J2 HTTP/1.1" 200 24062
urllib3.connectionpool:DEBUG:2022-10-04 20:10:51,859:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:52,392:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:10:52,535:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:10:53,215:https://www.newegg.com:443 "GET /fluance-xl8f/p/0S6-004W-000J5 HTTP/1.1" 200 24501
urllib3.connectionpool:DEBUG:2022-10-04 20:11:02,145:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:11:02,782:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:11:02,975:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:11:03,315:https://www.newegg.com:443 "GET /fluance-xl8fw/p/0S6-004W-000J2 HTTP/1.1" 200 24062
urllib3.connectionpool:DEBUG:2022-10-04 20:11:12,045:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:11:12,527:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:11:12,666:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:11:13,139:https://www.newegg.com:443 "GET /fluance-xl8f/p/0S6-004W-000J5 HTTP/1.1" 200 24501
urllib3.connectionpool:DEBUG:2022-10-04 20:11:22,157:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:11:23,035:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:11:23,192:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:11:23,942:https://www.newegg.com:443 "GET /fluance-hffw/p/0N6-0174-00010 HTTP/1.1" 200 24380
urllib3.connectionpool:DEBUG:2022-10-04 20:11:32,760:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 20:11:33,328:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 20:11:33,681:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-04 20:11:34,352:https://www.newegg.com:443 "GET /fluance-hff/p/0N6-0174-00011 HTTP/1.1" 200 25113
urllib3.connectionpool:DEBUG:2022-10-04 22:56:46,254:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 22:56:46,882:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 22:56:47,044:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 22:56:47,440:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AJv2xBSfZoPwFQeY9m2RlhnlAXk6zLqOsRxX58kxLWxA&qid=1664904357&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 503 1203
urllib3.connectionpool:DEBUG:2022-10-04 22:57:40,972:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 22:57:41,644:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 22:57:41,795:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 22:57:42,582:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AJv2xBSfZoPwFQeY9m2RlhnlAXk6zLqOsRxX58kxLWxA&qid=1664904357&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 22:59:45,070:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 22:59:45,590:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 22:59:45,750:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 22:59:46,665:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AJv2xBSfZoPwFQeY9m2RlhnlAXk6zLqOsRxX58kxLWxA&qid=1664904357&rnid=172563&ref=sr_nr_n_4 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:00:16,169:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 23:00:16,649:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:00:16,808:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 23:00:17,488:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AJv2xBSfZoPwFQeY9m2RlhnlAXk6zLqOsRxX58kxLWxA&qid=1664904357&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:01:58,933:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 23:01:59,454:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:01:59,749:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 23:02:00,594:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011&dc&ds=v1%3Acnj5e5wMF7gzPrL54jV8emwqe65y1czvO%2FYKWIgk5bI&qid=1664904642&rnid=9977442011&ref=sr_nr_n_2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:02:11,573:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 23:02:12,107:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:02:12,265:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 23:02:14,019:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&page=3&qid=1664904691&rnid=12097481011&ref=sr_pg_3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&page=3&qid=1664904691&rnid=12097481011&ref=sr_pg_3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&page=3&qid=1664904691&rnid=12097481011&ref=sr_pg_3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 23:02:14,053:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 23:02:14,767:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&page=3&qid=1664904691&rnid=12097481011&ref=sr_pg_3 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:06:07,215:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 23:06:07,897:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:06:08,061:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 23:06:09,507:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236454011&dc&ds=v1%3ARZ9lAex%2F27TcKKaYPmZkmFIHrWwzQJUN%2BBu5DNJDfs4&qid=1664904908&rnid=12097481011&ref=sr_nr_n_2&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236454011&dc&ds=v1%3ARZ9lAex%2F27TcKKaYPmZkmFIHrWwzQJUN%2BBu5DNJDfs4&qid=1664904908&rnid=12097481011&ref=sr_nr_n_2&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236454011&dc&ds=v1%3ARZ9lAex%2F27TcKKaYPmZkmFIHrWwzQJUN%2BBu5DNJDfs4&qid=1664904908&rnid=12097481011&ref=sr_nr_n_2&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 23:06:09,528:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 23:06:10,061:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236454011&dc&ds=v1%3ARZ9lAex%2F27TcKKaYPmZkmFIHrWwzQJUN%2BBu5DNJDfs4&qid=1664904908&rnid=12097481011&ref=sr_nr_n_2&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:07:57,423:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 23:07:57,970:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:07:58,265:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 23:07:59,727:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236454011&dc&ds=v1%3ARZ9lAex%2F27TcKKaYPmZkmFIHrWwzQJUN%2BBu5DNJDfs4&qid=1664904908&rnid=12097481011&ref=sr_nr_n_2&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236454011&dc&ds=v1%3ARZ9lAex%2F27TcKKaYPmZkmFIHrWwzQJUN%2BBu5DNJDfs4&qid=1664904908&rnid=12097481011&ref=sr_nr_n_2&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236454011&dc&ds=v1%3ARZ9lAex%2F27TcKKaYPmZkmFIHrWwzQJUN%2BBu5DNJDfs4&qid=1664904908&rnid=12097481011&ref=sr_nr_n_2&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 23:07:59,749:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 23:08:00,862:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236454011&dc&ds=v1%3ARZ9lAex%2F27TcKKaYPmZkmFIHrWwzQJUN%2BBu5DNJDfs4&qid=1664904908&rnid=12097481011&ref=sr_nr_n_2&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:09:09,458:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 23:09:10,021:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:09:10,219:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 23:09:11,670:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 23:09:11,690:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 23:09:12,916:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:09:13,688:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 23:09:14,213:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:09:14,354:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 23:09:15,795:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 23:09:15,799:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 23:09:16,544:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:09:17,301:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-04 23:09:17,809:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-04 23:09:17,948:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-04 23:09:19,390:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-04 23:09:19,394:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-04 23:09:20,133:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A9977442011%2Cn%3A12097481011%2Cn%3A3236452011&dc&ds=v1%3A5SDkCLjWeOZSaIXw%2FSDmqWR3Nd6zvrex1KU2gKQVK%2BY&qid=1664905130&rnid=12097481011&ref=sr_nr_n_1&page=3 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-05 22:50:37,708:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-05 22:50:38,744:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
root:ERROR:2022-10-05 22:50:38,884:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,898:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,899:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,900:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,901:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,902:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,903:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,904:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,905:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:50:38,906:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
urllib3.connectionpool:DEBUG:2022-10-05 22:51:50,093:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-05 22:51:50,643:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
root:ERROR:2022-10-05 22:51:50,784:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,794:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,795:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,796:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,798:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,799:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,801:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,802:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,803:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
root:ERROR:2022-10-05 22:51:50,804:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
urllib3.connectionpool:DEBUG:2022-10-05 22:52:10,390:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-05 22:52:10,890:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
root:ERROR:2022-10-05 22:52:11,038:Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 573, in request
    prep = self.prepare_request(req)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'sfs': No scheme supplied. Perhaps you meant http://sfs?
urllib3.connectionpool:DEBUG:2022-10-05 22:53:22,370:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-05 22:53:22,884:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-05 22:55:36,668:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,261:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,406:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,664:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1600>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD1600>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1600>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1600>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,694:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,723:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD16F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD16F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD16F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD16F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,726:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,754:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD18A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD18A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD18A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD18A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,758:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,786:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1630>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD1630>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1630>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1630>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,789:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,817:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD1750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,820:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,848:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1930>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD1930>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1930>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1930>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,851:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,880:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD1810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,883:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,911:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1960>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD1960>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1960>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD1960>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,914:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,948:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD18D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD18D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD18D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD18D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:37,951:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:37,979:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD15A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B824BD15A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD15A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B824BD15A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:55:49,858:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-05 22:55:50,324:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-05 22:55:50,470:Starting new HTTPS connection (1): www.asdsfdsd.com:443
root:ERROR:2022-10-05 22:55:50,499:HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000017D249510C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x0000017D249510C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000017D249510C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.asdsfdsd.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000017D249510C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
urllib3.connectionpool:DEBUG:2022-10-05 22:58:41,501:Starting new HTTPS connection (1): www.googl.com:443
urllib3.connection:WARNING:2022-10-05 22:58:42,225:Certificate did not match expected hostname: www.googl.com. Certificate: {'subject': ((('commonName', 'google.com'),),), 'issuer': ((('countryName', 'US'),), (('organizationName', 'Google Trust Services LLC'),), (('commonName', 'GTS CA 1C3'),)), 'version': 3, 'serialNumber': 'B5D6F8EAFF7A0D740A86482C98D89C3C', 'notBefore': 'Sep 12 08:20:35 2022 GMT', 'notAfter': 'Dec  5 08:20:34 2022 GMT', 'subjectAltName': (('DNS', 'google.com'), ('DNS', '*.appengine.google.com'), ('DNS', '*.bdn.dev'), ('DNS', '*.origin-test.bdn.dev'), ('DNS', '*.cloud.google.com'), ('DNS', '*.crowdsource.google.com'), ('DNS', '*.datacompute.google.com'), ('DNS', '*.google.ca'), ('DNS', '*.google.cl'), ('DNS', '*.google.co.in'), ('DNS', '*.google.co.jp'), ('DNS', '*.google.co.uk'), ('DNS', '*.google.com.ar'), ('DNS', '*.google.com.au'), ('DNS', '*.google.com.br'), ('DNS', '*.google.com.co'), ('DNS', '*.google.com.mx'), ('DNS', '*.google.com.tr'), ('DNS', '*.google.com.vn'), ('DNS', '*.google.de'), ('DNS', '*.google.es'), ('DNS', '*.google.fr'), ('DNS', '*.google.hu'), ('DNS', '*.google.it'), ('DNS', '*.google.nl'), ('DNS', '*.google.pl'), ('DNS', '*.google.pt'), ('DNS', '*.googleadapis.com'), ('DNS', '*.googleapis.cn'), ('DNS', '*.googlevideo.com'), ('DNS', '*.gstatic.cn'), ('DNS', '*.gstatic-cn.com'), ('DNS', 'googlecnapps.cn'), ('DNS', '*.googlecnapps.cn'), ('DNS', 'googleapps-cn.com'), ('DNS', '*.googleapps-cn.com'), ('DNS', 'gkecnapps.cn'), ('DNS', '*.gkecnapps.cn'), ('DNS', 'googledownloads.cn'), ('DNS', '*.googledownloads.cn'), ('DNS', 'recaptcha.net.cn'), ('DNS', '*.recaptcha.net.cn'), ('DNS', 'recaptcha-cn.net'), ('DNS', '*.recaptcha-cn.net'), ('DNS', 'widevine.cn'), ('DNS', '*.widevine.cn'), ('DNS', 'ampproject.org.cn'), ('DNS', '*.ampproject.org.cn'), ('DNS', 'ampproject.net.cn'), ('DNS', '*.ampproject.net.cn'), ('DNS', 'google-analytics-cn.com'), ('DNS', '*.google-analytics-cn.com'), ('DNS', 'googleadservices-cn.com'), ('DNS', '*.googleadservices-cn.com'), ('DNS', 'googlevads-cn.com'), ('DNS', '*.googlevads-cn.com'), ('DNS', 'googleapis-cn.com'), ('DNS', '*.googleapis-cn.com'), ('DNS', 'googleoptimize-cn.com'), ('DNS', '*.googleoptimize-cn.com'), ('DNS', 'doubleclick-cn.net'), ('DNS', '*.doubleclick-cn.net'), ('DNS', '*.fls.doubleclick-cn.net'), ('DNS', '*.g.doubleclick-cn.net'), ('DNS', 'doubleclick.cn'), ('DNS', '*.doubleclick.cn'), ('DNS', '*.fls.doubleclick.cn'), ('DNS', '*.g.doubleclick.cn'), ('DNS', 'dartsearch-cn.net'), ('DNS', '*.dartsearch-cn.net'), ('DNS', 'googletraveladservices-cn.com'), ('DNS', '*.googletraveladservices-cn.com'), ('DNS', 'googletagservices-cn.com'), ('DNS', '*.googletagservices-cn.com'), ('DNS', 'googletagmanager-cn.com'), ('DNS', '*.googletagmanager-cn.com'), ('DNS', 'googlesyndication-cn.com'), ('DNS', '*.googlesyndication-cn.com'), ('DNS', '*.safeframe.googlesyndication-cn.com'), ('DNS', 'app-measurement-cn.com'), ('DNS', '*.app-measurement-cn.com'), ('DNS', 'gvt1-cn.com'), ('DNS', '*.gvt1-cn.com'), ('DNS', 'gvt2-cn.com'), ('DNS', '*.gvt2-cn.com'), ('DNS', '2mdn-cn.net'), ('DNS', '*.2mdn-cn.net'), ('DNS', 'googleflights-cn.net'), ('DNS', '*.googleflights-cn.net'), ('DNS', 'admob-cn.com'), ('DNS', '*.admob-cn.com'), ('DNS', '*.gstatic.com'), ('DNS', '*.metric.gstatic.com'), ('DNS', '*.gvt1.com'), ('DNS', '*.gcpcdn.gvt1.com'), ('DNS', '*.gvt2.com'), ('DNS', '*.gcp.gvt2.com'), ('DNS', '*.url.google.com'), ('DNS', '*.youtube-nocookie.com'), ('DNS', '*.ytimg.com'), ('DNS', 'android.com'), ('DNS', '*.android.com'), ('DNS', '*.flash.android.com'), ('DNS', 'g.cn'), ('DNS', '*.g.cn'), ('DNS', 'g.co'), ('DNS', '*.g.co'), ('DNS', 'goo.gl'), ('DNS', 'www.goo.gl'), ('DNS', 'google-analytics.com'), ('DNS', '*.google-analytics.com'), ('DNS', '*.google.com'), ('DNS', 'googlecommerce.com'), ('DNS', '*.googlecommerce.com'), ('DNS', 'ggpht.cn'), ('DNS', '*.ggpht.cn'), ('DNS', 'urchin.com'), ('DNS', '*.urchin.com'), ('DNS', 'youtu.be'), ('DNS', 'youtube.com'), ('DNS', '*.youtube.com'), ('DNS', 'youtubeeducation.com'), ('DNS', '*.youtubeeducation.com'), ('DNS', 'youtubekids.com'), ('DNS', '*.youtubekids.com'), ('DNS', 'yt.be'), ('DNS', '*.yt.be'), ('DNS', 'android.clients.google.com'), ('DNS', 'developer.android.google.cn'), ('DNS', 'developers.android.google.cn'), ('DNS', 'source.android.google.cn'), ('DNS', 'google.ac'), ('DNS', '*.google.ac'), ('DNS', 'google.ad'), ('DNS', '*.google.ad'), ('DNS', 'google.ae'), ('DNS', '*.google.ae'), ('DNS', 'google.af'), ('DNS', '*.google.af'), ('DNS', 'google.ag'), ('DNS', '*.google.ag'), ('DNS', 'google.ai'), ('DNS', '*.google.ai'), ('DNS', 'google.al'), ('DNS', '*.google.al'), ('DNS', 'google.am'), ('DNS', '*.google.am'), ('DNS', 'google.as'), ('DNS', '*.google.as'), ('DNS', 'google.at'), ('DNS', '*.google.at'), ('DNS', 'google.az'), ('DNS', '*.google.az'), ('DNS', 'google.ba'), ('DNS', '*.google.ba'), ('DNS', 'google.be'), ('DNS', '*.google.be'), ('DNS', 'google.bf'), ('DNS', '*.google.bf'), ('DNS', 'google.bg'), ('DNS', '*.google.bg'), ('DNS', 'google.bi'), ('DNS', '*.google.bi'), ('DNS', 'google.bj'), ('DNS', '*.google.bj'), ('DNS', 'google.bs'), ('DNS', '*.google.bs'), ('DNS', 'google.bt'), ('DNS', '*.google.bt'), ('DNS', 'google.by'), ('DNS', '*.google.by'), ('DNS', 'google.bzh'), ('DNS', '*.google.bzh'), ('DNS', 'google.ca'), ('DNS', 'google.cat'), ('DNS', '*.google.cat'), ('DNS', 'google.cc'), ('DNS', '*.google.cc'), ('DNS', 'google.cd'), ('DNS', '*.google.cd'), ('DNS', 'google.cf'), ('DNS', '*.google.cf'), ('DNS', 'google.cg'), ('DNS', '*.google.cg'), ('DNS', 'google.ch'), ('DNS', '*.google.ch'), ('DNS', 'google.ci'), ('DNS', '*.google.ci'), ('DNS', 'google.cl'), ('DNS', 'google.cm'), ('DNS', '*.google.cm'), ('DNS', 'google.cn'), ('DNS', '*.google.cn'), ('DNS', 'google.co.ao'), ('DNS', '*.google.co.ao'), ('DNS', 'google.co.bw'), ('DNS', '*.google.co.bw'), ('DNS', 'google.co.ck'), ('DNS', '*.google.co.ck'), ('DNS', 'google.co.cr'), ('DNS', '*.google.co.cr'), ('DNS', 'google.co.hu'), ('DNS', '*.google.co.hu'), ('DNS', 'google.co.id'), ('DNS', '*.google.co.id'), ('DNS', 'google.co.il'), ('DNS', '*.google.co.il'), ('DNS', 'google.co.im'), ('DNS', '*.google.co.im'), ('DNS', 'google.co.in'), ('DNS', 'google.co.je'), ('DNS', '*.google.co.je'), ('DNS', 'google.co.jp'), ('DNS', 'google.co.ke'), ('DNS', '*.google.co.ke'), ('DNS', 'google.co.kr'), ('DNS', '*.google.co.kr'), ('DNS', 'google.co.ls'), ('DNS', '*.google.co.ls'), ('DNS', 'google.co.ma'), ('DNS', '*.google.co.ma'), ('DNS', 'google.co.mz'), ('DNS', '*.google.co.mz'), ('DNS', 'google.co.nz'), ('DNS', '*.google.co.nz'), ('DNS', 'google.co.th'), ('DNS', '*.google.co.th'), ('DNS', 'google.co.tz'), ('DNS', '*.google.co.tz'), ('DNS', 'google.co.ug'), ('DNS', '*.google.co.ug'), ('DNS', 'google.co.uk'), ('DNS', 'google.co.uz'), ('DNS', '*.google.co.uz'), ('DNS', 'google.co.ve'), ('DNS', '*.google.co.ve'), ('DNS', 'google.co.vi'), ('DNS', '*.google.co.vi'), ('DNS', 'google.co.za'), ('DNS', '*.google.co.za'), ('DNS', 'google.co.zm'), ('DNS', '*.google.co.zm'), ('DNS', 'google.co.zw'), ('DNS', '*.google.co.zw'), ('DNS', 'google.com.af'), ('DNS', '*.google.com.af'), ('DNS', 'google.com.ag'), ('DNS', '*.google.com.ag'), ('DNS', 'google.com.ai'), ('DNS', '*.google.com.ai'), ('DNS', 'google.com.ar'), ('DNS', 'google.com.au'), ('DNS', 'google.com.bd'), ('DNS', '*.google.com.bd'), ('DNS', 'google.com.bh'), ('DNS', '*.google.com.bh'), ('DNS', 'google.com.bn'), ('DNS', '*.google.com.bn'), ('DNS', 'google.com.bo'), ('DNS', '*.google.com.bo'), ('DNS', 'google.com.br'), ('DNS', 'google.com.by'), ('DNS', '*.google.com.by'), ('DNS', 'google.com.bz'), ('DNS', '*.google.com.bz'), ('DNS', 'google.com.co'), ('DNS', 'google.com.cu'), ('DNS', '*.google.com.cu'), ('DNS', 'google.com.cy'), ('DNS', '*.google.com.cy'), ('DNS', 'google.com.do'), ('DNS', '*.google.com.do'), ('DNS', 'google.com.ec'), ('DNS', '*.google.com.ec'), ('DNS', 'google.com.eg'), ('DNS', '*.google.com.eg'), ('DNS', 'google.com.et'), ('DNS', '*.google.com.et'), ('DNS', 'google.com.fj'), ('DNS', '*.google.com.fj'), ('DNS', 'google.com.ge'), ('DNS', '*.google.com.ge'), ('DNS', 'google.com.gh'), ('DNS', '*.google.com.gh'), ('DNS', 'google.com.gi'), ('DNS', '*.google.com.gi'), ('DNS', 'google.com.gr'), ('DNS', '*.google.com.gr'), ('DNS', 'google.com.gt'), ('DNS', '*.google.com.gt'), ('DNS', 'google.com.hk'), ('DNS', '*.google.com.hk'), ('DNS', 'google.com.iq'), ('DNS', '*.google.com.iq'), ('DNS', 'google.com.jm'), ('DNS', '*.google.com.jm'), ('DNS', 'google.com.jo'), ('DNS', '*.google.com.jo'), ('DNS', 'google.com.kh'), ('DNS', '*.google.com.kh'), ('DNS', 'google.com.kw'), ('DNS', '*.google.com.kw'), ('DNS', 'google.com.lb'), ('DNS', '*.google.com.lb'), ('DNS', 'google.com.ly'), ('DNS', '*.google.com.ly'), ('DNS', 'google.com.mm'), ('DNS', '*.google.com.mm'), ('DNS', 'google.com.mt'), ('DNS', '*.google.com.mt'), ('DNS', 'google.com.mx'), ('DNS', 'google.com.my'), ('DNS', '*.google.com.my'), ('DNS', 'google.com.na'), ('DNS', '*.google.com.na'), ('DNS', 'google.com.nf'), ('DNS', '*.google.com.nf'), ('DNS', 'google.com.ng'), ('DNS', '*.google.com.ng'), ('DNS', 'google.com.ni'), ('DNS', '*.google.com.ni'), ('DNS', 'google.com.np'), ('DNS', '*.google.com.np'), ('DNS', 'google.com.nr'), ('DNS', '*.google.com.nr'), ('DNS', 'google.com.om'), ('DNS', '*.google.com.om'), ('DNS', 'google.com.pa'), ('DNS', '*.google.com.pa'), ('DNS', 'google.com.pe'), ('DNS', '*.google.com.pe'), ('DNS', 'google.com.pg'), ('DNS', '*.google.com.pg'), ('DNS', 'google.com.ph'), ('DNS', '*.google.com.ph'), ('DNS', 'google.com.pk'), ('DNS', '*.google.com.pk'), ('DNS', 'google.com.pl'), ('DNS', '*.google.com.pl'), ('DNS', 'google.com.pr'), ('DNS', '*.google.com.pr'), ('DNS', 'google.com.py'), ('DNS', '*.google.com.py'), ('DNS', 'google.com.qa'), ('DNS', '*.google.com.qa'), ('DNS', 'google.com.ru'), ('DNS', '*.google.com.ru'), ('DNS', 'google.com.sa'), ('DNS', '*.google.com.sa'), ('DNS', 'google.com.sb'), ('DNS', '*.google.com.sb'), ('DNS', 'google.com.sg'), ('DNS', '*.google.com.sg'), ('DNS', 'google.com.sl'), ('DNS', '*.google.com.sl'), ('DNS', 'google.com.sv'), ('DNS', '*.google.com.sv'), ('DNS', 'google.com.tj'), ('DNS', '*.google.com.tj'), ('DNS', 'google.com.tn'), ('DNS', '*.google.com.tn'), ('DNS', 'google.com.tr'), ('DNS', 'google.com.tw'), ('DNS', '*.google.com.tw'), ('DNS', 'google.com.ua'), ('DNS', '*.google.com.ua'), ('DNS', 'google.com.uy'), ('DNS', '*.google.com.uy'), ('DNS', 'google.com.vc'), ('DNS', '*.google.com.vc'), ('DNS', 'google.com.ve'), ('DNS', '*.google.com.ve'), ('DNS', 'google.com.vn'), ('DNS', 'google.cv'), ('DNS', '*.google.cv'), ('DNS', 'google.cz'), ('DNS', '*.google.cz'), ('DNS', 'google.de'), ('DNS', 'google.dj'), ('DNS', '*.google.dj'), ('DNS', 'google.dk'), ('DNS', '*.google.dk'), ('DNS', 'google.dm'), ('DNS', '*.google.dm'), ('DNS', 'google.dz'), ('DNS', '*.google.dz'), ('DNS', 'google.ee'), ('DNS', '*.google.ee'), ('DNS', 'google.es'), ('DNS', 'google.eus'), ('DNS', '*.google.eus'), ('DNS', 'google.fi'), ('DNS', '*.google.fi'), ('DNS', 'google.fm'), ('DNS', '*.google.fm'), ('DNS', 'google.fr'), ('DNS', 'google.frl'), ('DNS', '*.google.frl'), ('DNS', 'google.ga'), ('DNS', '*.google.ga'), ('DNS', 'google.gal'), ('DNS', '*.google.gal'), ('DNS', 'google.ge'), ('DNS', '*.google.ge'), ('DNS', 'google.gg'), ('DNS', '*.google.gg'), ('DNS', 'google.gl'), ('DNS', '*.google.gl'), ('DNS', 'google.gm'), ('DNS', '*.google.gm'), ('DNS', 'google.gp'), ('DNS', '*.google.gp'), ('DNS', 'google.gr'), ('DNS', '*.google.gr'), ('DNS', 'google.gy'), ('DNS', '*.google.gy'), ('DNS', 'google.hk'), ('DNS', '*.google.hk'), ('DNS', 'google.hn'), ('DNS', '*.google.hn'), ('DNS', 'google.hr'), ('DNS', '*.google.hr'), ('DNS', 'google.ht'), ('DNS', '*.google.ht'), ('DNS', 'google.hu'), ('DNS', 'google.ie'), ('DNS', '*.google.ie'), ('DNS', 'google.im'), ('DNS', '*.google.im'), ('DNS', 'google.in'), ('DNS', '*.google.in'), ('DNS', 'google.info'), ('DNS', '*.google.info'), ('DNS', 'google.iq'), ('DNS', '*.google.iq'), ('DNS', 'google.ir'), ('DNS', '*.google.ir'), ('DNS', 'google.is'), ('DNS', '*.google.is'), ('DNS', 'google.it'), ('DNS', 'google.it.ao'), ('DNS', '*.google.it.ao'), ('DNS', 'google.je'), ('DNS', '*.google.je'), ('DNS', 'google.jo'), ('DNS', '*.google.jo'), ('DNS', 'google.jobs'), ('DNS', '*.google.jobs'), ('DNS', 'google.jp'), ('DNS', '*.google.jp'), ('DNS', 'google.kg'), ('DNS', '*.google.kg'), ('DNS', 'google.ki'), ('DNS', '*.google.ki'), ('DNS', 'google.kz'), ('DNS', '*.google.kz'), ('DNS', 'google.la'), ('DNS', '*.google.la'), ('DNS', 'google.li'), ('DNS', '*.google.li'), ('DNS', 'google.lk'), ('DNS', '*.google.lk'), ('DNS', 'google.lt'), ('DNS', '*.google.lt'), ('DNS', 'google.lu'), ('DNS', '*.google.lu'), ('DNS', 'google.lv'), ('DNS', '*.google.lv'), ('DNS', 'google.md'), ('DNS', '*.google.md'), ('DNS', 'google.me'), ('DNS', '*.google.me'), ('DNS', 'google.mg'), ('DNS', '*.google.mg'), ('DNS', 'google.mk'), ('DNS', '*.google.mk'), ('DNS', 'google.ml'), ('DNS', '*.google.ml'), ('DNS', 'google.mn'), ('DNS', '*.google.mn'), ('DNS', 'google.ms'), ('DNS', '*.google.ms'), ('DNS', 'google.mu'), ('DNS', '*.google.mu'), ('DNS', 'google.mv'), ('DNS', '*.google.mv'), ('DNS', 'google.mw'), ('DNS', '*.google.mw'), ('DNS', 'google.ne'), ('DNS', '*.google.ne'), ('DNS', 'google.ne.jp'), ('DNS', '*.google.ne.jp'), ('DNS', 'google.net'), ('DNS', '*.google.net'), ('DNS', 'google.ng'), ('DNS', '*.google.ng'), ('DNS', 'google.nl'), ('DNS', 'google.no'), ('DNS', '*.google.no'), ('DNS', 'google.nr'), ('DNS', '*.google.nr'), ('DNS', 'google.nu'), ('DNS', '*.google.nu'), ('DNS', 'google.off.ai'), ('DNS', '*.google.off.ai'), ('DNS', 'google.pk'), ('DNS', '*.google.pk'), ('DNS', 'google.pl'), ('DNS', 'google.pn'), ('DNS', '*.google.pn'), ('DNS', 'google.ps'), ('DNS', '*.google.ps'), ('DNS', 'google.pt'), ('DNS', 'google.ro'), ('DNS', '*.google.ro'), ('DNS', 'google.rs'), ('DNS', '*.google.rs'), ('DNS', 'google.ru'), ('DNS', '*.google.ru'), ('DNS', 'google.rw'), ('DNS', '*.google.rw'), ('DNS', 'google.sc'), ('DNS', '*.google.sc'), ('DNS', 'google.se'), ('DNS', '*.google.se'), ('DNS', 'google.sh'), ('DNS', '*.google.sh'), ('DNS', 'google.si'), ('DNS', '*.google.si'), ('DNS', 'google.sk'), ('DNS', '*.google.sk'), ('DNS', 'google.sm'), ('DNS', '*.google.sm'), ('DNS', 'google.sn'), ('DNS', '*.google.sn'), ('DNS', 'google.so'), ('DNS', '*.google.so'), ('DNS', 'google.sr'), ('DNS', '*.google.sr'), ('DNS', 'google.st'), ('DNS', '*.google.st'), ('DNS', 'google.td'), ('DNS', '*.google.td'), ('DNS', 'google.tel'), ('DNS', '*.google.tel'), ('DNS', 'google.tg'), ('DNS', '*.google.tg'), ('DNS', 'google.tk'), ('DNS', '*.google.tk'), ('DNS', 'google.tl'), ('DNS', '*.google.tl'), ('DNS', 'google.tm'), ('DNS', '*.google.tm'), ('DNS', 'google.tn'), ('DNS', '*.google.tn'), ('DNS', 'google.to'), ('DNS', '*.google.to'), ('DNS', 'google.tt'), ('DNS', '*.google.tt'), ('DNS', 'google.us'), ('DNS', '*.google.us'), ('DNS', 'google.uz'), ('DNS', '*.google.uz'), ('DNS', 'google.vg'), ('DNS', '*.google.vg'), ('DNS', 'google.vu'), ('DNS', '*.google.vu'), ('DNS', 'google.ws'), ('DNS', '*.google.ws'), ('DNS', 'gstatic.com'), ('DNS', '*.2mdn.net'), ('DNS', '*.au.doubleclick.net'), ('DNS', '*.cc-dt.com'), ('DNS', '*.de.doubleclick.net'), ('DNS', 'doubleclick.com'), ('DNS', '*.doubleclick.com'), ('DNS', '*.fls.doubleclick.net'), ('DNS', '*.fr.doubleclick.net'), ('DNS', '*.jp.doubleclick.net'), ('DNS', '*.uk.doubleclick.net'), ('DNS', 'ad.mo.doubleclick.net'), ('DNS', 'doubleclick.net'), ('DNS', '*.doubleclick.net'), ('DNS', '*.googleadsserving.cn'), ('DNS', '*.googleusercontent.cn'), ('DNS', '*.safenup.googleusercontent.cn'), ('DNS', 'google.ua'), ('DNS', '*.google.ua')), 'OCSP': ('http://ocsp.pki.goog/gts1c3',), 'caIssuers': ('http://pki.goog/repo/certs/gts1c3.der',), 'crlDistributionPoints': ('http://crls.pki.goog/gts1c3/QqFxbi9M48c.crl',)}
urllib3.connectionpool:DEBUG:2022-10-05 22:58:45,452:Starting new HTTPS connection (1): www.google.com:443
urllib3.connectionpool:DEBUG:2022-10-05 22:58:45,831:https://www.google.com:443 "GET / HTTP/1.1" 200 None
charset_normalizer:DEBUG:2022-10-05 22:58:46,123:Encoding detection: Found cp1250 as plausible (best-candidate) for content. With 13 alternatives.
root:ERROR:2022-10-06 01:00:26,742:list indices must be integers or slices, not str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\updater.py", line 41, in update_items
    url = item['sellers']['productLink']
TypeError: list indices must be integers or slices, not str
werkzeug:INFO:2022-10-06 01:00:26,758:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 01:00:26,758:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 01:00:31,582:127.0.0.1 - - [06/Oct/2022 01:00:31] "[33mGET / HTTP/1.1[0m" 404 -
werkzeug:INFO:2022-10-06 01:00:34,559:127.0.0.1 - - [06/Oct/2022 01:00:34] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
werkzeug:INFO:2022-10-06 01:00:46,902:127.0.0.1 - - [06/Oct/2022 01:00:46] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 01:00:46,916:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:00:46,917:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:00:47,570:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:00:47,603:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:00:47,710:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:00:47,845:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-06 01:01:08,821:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743AEC68C0>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 179, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000002743AEC68C0>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743AEC68C0>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 553, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743AEC68C0>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))
urllib3.connectionpool:DEBUG:2022-10-06 01:01:08,844:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-06 01:01:08,882:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743B24A530>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 179, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000002743B24A530>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743B24A530>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 553, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743B24A530>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))
urllib3.connectionpool:DEBUG:2022-10-06 01:01:08,885:Starting new HTTPS connection (1): www.amazon.com:443
root:ERROR:2022-10-06 01:01:09,646:HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:997)')))
root:ERROR:2022-10-06 01:01:09,650:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-06 01:01:09,657:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:09,660:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:10,633:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:01:10,920:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 65923
urllib3.connectionpool:DEBUG:2022-10-06 01:01:11,127:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:11,251:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:11,656:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:01:11,791:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:01:11,793:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:11,923:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:12,761:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:01:27,987:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:01:28,217:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:28,684:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:01:28,811:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-06 01:01:49,845:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=2 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743ADBA740>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 179, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x000002743ADBA740>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=2 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743ADBA740>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 553, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=2 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002743ADBA740>, 'Connection to 20.212.168.206 timed out. (connect timeout=None)'))
urllib3.connectionpool:DEBUG:2022-10-06 01:01:49,848:Starting new HTTPS connection (1): www.newegg.com:443
root:ERROR:2022-10-06 01:01:50,469:HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connection.py", line 414, in connect
    self.sock = ssl_wrap_socket(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 512, in wrap_socket
    return self.sslsocket_class._create(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1070, in _create
    self.do_handshake()
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\ssl.py", line 1341, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\send_request.py", line 75, in send_request
    page = requests.get(url, headers=HEADERS, proxies=ip)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.newegg.com', port=443): Max retries exceeded with url: /p/pl?N=100008225%20600030002&page=2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
urllib3.connectionpool:DEBUG:2022-10-06 01:01:50,473:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:51,640:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 36363
urllib3.connectionpool:DEBUG:2022-10-06 01:01:51,870:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:01:52,424:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:01:52,562:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:02:02,572:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 25078
urllib3.connectionpool:DEBUG:2022-10-06 01:02:11,590:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:02:12,137:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:02:12,323:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:02:12,892:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 25078
urllib3.connectionpool:DEBUG:2022-10-06 01:02:21,831:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:02:22,351:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:02:22,528:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:02:23,099:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 22166
urllib3.connectionpool:DEBUG:2022-10-06 01:02:33,546:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:02:34,049:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:02:34,260:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:02:36,062:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24228
werkzeug:INFO:2022-10-06 01:05:49,705:127.0.0.1 - - [06/Oct/2022 01:05:49] "GET /update HTTP/1.1" 200 -
root:ERROR:2022-10-06 01:05:54,129:list indices must be integers or slices, not str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\updater.py", line 41, in update_items
    url = item['sellers']['productLink']
TypeError: list indices must be integers or slices, not str
urllib3.connectionpool:DEBUG:2022-10-06 01:05:54,131:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:05:54,631:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:05:54,780:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:05:55,716:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24228
urllib3.connectionpool:DEBUG:2022-10-06 01:05:55,786:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:05:56,253:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:05:56,390:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:05:56,711:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24228
urllib3.connectionpool:DEBUG:2022-10-06 01:05:56,780:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:05:57,339:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:05:57,526:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:05:57,862:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 22166
urllib3.connectionpool:DEBUG:2022-10-06 01:05:57,909:Starting new HTTPS connection (1): free-proxy-list.net:443
urllib3.connectionpool:DEBUG:2022-10-06 01:05:58,354:https://free-proxy-list.net:443 "GET / HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 01:05:58,493:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 01:05:59,159:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 25078
root:ERROR:2022-10-06 14:04:01,416:list indices must be integers or slices, not str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\updater.py", line 41, in update_items
    url = item['sellers']['productLink']
TypeError: list indices must be integers or slices, not str
urllib3.connectionpool:DEBUG:2022-10-06 14:04:01,426:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:04:03,447:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
urllib3.connectionpool:DEBUG:2022-10-06 14:04:04,106:Starting new HTTPS connection (1): www.newegg.com:443
werkzeug:INFO:2022-10-06 14:04:28,867:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 14:04:28,868:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 14:04:47,099:127.0.0.1 - - [06/Oct/2022 14:04:47] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 14:04:47,121:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:04:47,123:Starting new HTTPS connection (1): www.amazon.com:443
werkzeug:INFO:2022-10-06 14:04:47,159:127.0.0.1 - - [06/Oct/2022 14:04:47] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
urllib3.connectionpool:DEBUG:2022-10-06 14:04:48,689:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:04:48,879:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:04:49,375:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:04:49,494:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:04:50,660:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:04:50,930:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:04:51,512:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:05:04,272:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 35765
urllib3.connectionpool:DEBUG:2022-10-06 14:05:04,599:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:05:37,616:https://www.bestbuy.com:443 "GET /site/speakers/floor-speakers/abcat0205003.c?id=abcat0205003 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:05:38,267:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:05:40,521:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=2&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:05:41,235:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:05:43,285:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=3&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:05:43,980:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:05:55,472:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=4&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:05:56,220:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:05:58,216:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=5&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:05:58,879:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:06:10,171:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:06:10,847:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:06:12,627:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=7&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
root:ERROR:2022-10-06 14:06:13,152:can only concatenate str (not "NoneType") to str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\crawler.py", line 113, in next_page_bestbuy
    return "https://www.bestbuy.com" + next_page_link.get('href')
TypeError: can only concatenate str (not "NoneType") to str
urllib3.connectionpool:DEBUG:2022-10-06 14:06:13,676:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:06:15,329:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
urllib3.connectionpool:DEBUG:2022-10-06 14:06:36,314:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:06:37,433:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
urllib3.connectionpool:DEBUG:2022-10-06 14:06:58,297:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:07:00,034:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 21616
urllib3.connectionpool:DEBUG:2022-10-06 14:07:09,303:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:07:10,507:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
urllib3.connectionpool:DEBUG:2022-10-06 14:07:37,278:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:07:38,894:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
urllib3.connectionpool:DEBUG:2022-10-06 14:08:00,890:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:08:02,446:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
urllib3.connectionpool:DEBUG:2022-10-06 14:08:11,340:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:08:12,529:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
werkzeug:INFO:2022-10-06 14:15:12,341:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 14:15:12,341:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 14:15:21,441:127.0.0.1 - - [06/Oct/2022 14:15:21] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 14:15:21,451:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:15:23,021:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:15:23,766:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:15:36,303:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:15:36,996:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:15:39,994:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:15:40,448:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:15:46,214:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:15:46,781:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:15:59,628:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 35937
urllib3.connectionpool:DEBUG:2022-10-06 14:15:59,955:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:02,709:https://www.bestbuy.com:443 "GET /site/speakers/floor-speakers/abcat0205003.c?id=abcat0205003 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:16:03,355:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:16,524:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=2&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:16:17,268:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:19,391:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=3&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:16:20,098:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:30,716:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=4&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:16:31,431:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:33,473:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=5&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:16:34,375:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:36,421:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 14:16:37,214:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:39,040:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=7&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
root:ERROR:2022-10-06 14:16:39,562:can only concatenate str (not "NoneType") to str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\crawler.py", line 113, in next_page_bestbuy
    return "https://www.bestbuy.com" + next_page_link.get('href')
TypeError: can only concatenate str (not "NoneType") to str
urllib3.connectionpool:DEBUG:2022-10-06 14:16:40,542:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:41,707:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
urllib3.connectionpool:DEBUG:2022-10-06 14:16:51,610:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:16:52,526:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
urllib3.connectionpool:DEBUG:2022-10-06 14:17:24,759:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:17:26,153:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 21616
urllib3.connectionpool:DEBUG:2022-10-06 14:17:46,855:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:17:47,976:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
urllib3.connectionpool:DEBUG:2022-10-06 14:18:08,207:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:18:09,342:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
urllib3.connectionpool:DEBUG:2022-10-06 14:18:31,707:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:18:33,227:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
urllib3.connectionpool:DEBUG:2022-10-06 14:18:53,695:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 14:18:54,788:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 15:26:54,135:list indices must be integers or slices, not str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\updater.py", line 42, in update_items
    url = item['sellers']['productLink']
TypeError: list indices must be integers or slices, not str
urllib3.connectionpool:DEBUG:2022-10-06 15:26:54,157:Starting new HTTPS connection (1): www.newegg.com:443
werkzeug:INFO:2022-10-06 15:27:05,798:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 15:27:05,798:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 15:27:30,325:127.0.0.1 - - [06/Oct/2022 15:27:30] "[33mGET / HTTP/1.1[0m" 404 -
werkzeug:INFO:2022-10-06 15:28:25,249:127.0.0.1 - - [06/Oct/2022 15:28:25] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 15:28:25,260:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:26,787:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:28:27,589:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:40,147:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:28:40,857:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:43,064:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 67560
urllib3.connectionpool:DEBUG:2022-10-06 15:28:43,612:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:45,007:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:28:45,559:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:47,372:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 34520
urllib3.connectionpool:DEBUG:2022-10-06 15:28:47,713:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:50,186:https://www.bestbuy.com:443 "GET /site/speakers/floor-speakers/abcat0205003.c?id=abcat0205003 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:28:50,864:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:53,107:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=2&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:28:53,869:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:55,985:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=3&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:28:56,703:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:28:59,252:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=4&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:29:00,043:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:29:02,323:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=5&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:29:03,065:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:29:05,190:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:29:05,939:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:29:07,770:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=7&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
root:ERROR:2022-10-06 15:29:08,313:can only concatenate str (not "NoneType") to str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\crawler.py", line 106, in next_page_bestbuy
    return "https://www.bestbuy.com" + next_page_link.get('href')
TypeError: can only concatenate str (not "NoneType") to str
urllib3.connectionpool:DEBUG:2022-10-06 15:29:09,483:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:29:11,334:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
root:ERROR:2022-10-06 15:29:19,439:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:29:20,016:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:29:32,256:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
root:ERROR:2022-10-06 15:29:51,935:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:29:52,734:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:29:54,161:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 21616
root:ERROR:2022-10-06 15:30:13,646:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:30:13,921:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:30:15,357:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 15:30:35,006:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:30:35,037:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:30:36,480:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 15:30:56,158:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:30:58,016:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:30:59,570:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 15:31:18,974:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:31:19,005:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:31:20,535:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 15:31:47,256:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
werkzeug:INFO:2022-10-06 15:41:03,345:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 15:41:03,345:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 15:41:58,817:127.0.0.1 - - [06/Oct/2022 15:41:58] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 15:41:58,829:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:42:00,353:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:42:01,155:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:42:13,649:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:42:14,382:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:42:16,533:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 66530
urllib3.connectionpool:DEBUG:2022-10-06 15:42:17,082:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:42:18,478:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:42:19,097:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:42:23,004:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 34611
urllib3.connectionpool:DEBUG:2022-10-06 15:42:23,358:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:42:54,933:https://www.bestbuy.com:443 "GET /site/speakers/floor-speakers/abcat0205003.c?id=abcat0205003 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:42:55,642:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:42:58,599:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=2&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:42:59,314:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:43:31,079:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=3&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:43:31,787:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:43:34,357:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=4&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:43:35,148:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:43:37,372:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=5&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:43:38,053:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:43:48,612:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:43:49,296:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:43:51,153:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=7&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
root:ERROR:2022-10-06 15:43:51,720:can only concatenate str (not "NoneType") to str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\crawler.py", line 106, in next_page_bestbuy
    return "https://www.bestbuy.com" + next_page_link.get('href')
TypeError: can only concatenate str (not "NoneType") to str
urllib3.connectionpool:DEBUG:2022-10-06 15:43:52,378:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:43:53,880:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24123
root:ERROR:2022-10-06 15:44:13,568:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:44:14,172:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:44:15,285:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
root:ERROR:2022-10-06 15:44:46,082:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:44:46,759:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:44:48,143:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 21616
root:ERROR:2022-10-06 15:45:07,780:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:45:08,018:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:45:09,121:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 15:45:17,207:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:45:17,236:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:45:30,067:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 15:45:49,606:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:45:51,484:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:45:52,928:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 15:46:01,023:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:46:01,053:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:46:13,265:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 15:46:21,574:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
werkzeug:INFO:2022-10-06 15:51:37,913:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 15:51:37,913:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 15:52:26,057:127.0.0.1 - - [06/Oct/2022 15:52:26] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 15:52:26,064:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:27,642:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:52:28,447:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:29,614:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:52:30,327:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:32,263:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:52:32,844:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:34,309:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:52:34,861:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:36,152:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 34736
urllib3.connectionpool:DEBUG:2022-10-06 15:52:36,484:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:38,770:https://www.bestbuy.com:443 "GET /site/speakers/floor-speakers/abcat0205003.c?id=abcat0205003 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:52:39,456:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:41,271:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=2&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:52:41,999:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:54,998:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=3&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:52:55,720:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:52:57,452:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=4&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:52:58,224:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:53:08,955:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=5&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:53:09,658:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:53:12,639:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 15:53:13,335:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:53:26,225:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=7&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
root:ERROR:2022-10-06 15:53:26,784:can only concatenate str (not "NoneType") to str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\crawler.py", line 106, in next_page_bestbuy
    return "https://www.bestbuy.com" + next_page_link.get('href')
TypeError: can only concatenate str (not "NoneType") to str
urllib3.connectionpool:DEBUG:2022-10-06 15:53:27,410:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:53:28,553:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
root:ERROR:2022-10-06 15:53:48,294:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:53:48,875:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:53:50,093:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24123
root:ERROR:2022-10-06 15:53:59,617:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:54:00,455:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:54:01,357:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 21616
root:ERROR:2022-10-06 15:54:23,480:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:54:23,705:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:54:24,878:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 15:54:55,880:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:54:55,909:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:54:57,025:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 15:55:16,416:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:55:18,907:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:55:20,327:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 15:55:28,431:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 15:55:28,461:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 15:55:29,387:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 15:55:44,363:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 69, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
werkzeug:INFO:2022-10-06 16:09:58,056:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 16:09:58,057:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 16:18:08,111:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 16:18:08,112:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 16:18:44,446:127.0.0.1 - - [06/Oct/2022 16:18:44] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 16:18:44,464:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:18:46,736:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:18:47,526:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:18:49,017:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:18:49,736:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:18:51,538:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:18:52,012:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:19:04,881:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:19:05,520:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:19:06,824:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 34559
urllib3.connectionpool:DEBUG:2022-10-06 16:19:07,150:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:19:09,691:https://www.bestbuy.com:443 "GET /site/speakers/floor-speakers/abcat0205003.c?id=abcat0205003 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:19:10,398:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:19:28,748:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=2&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:19:29,435:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:19:36,205:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=3&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:19:36,892:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:19:50,344:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=4&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:19:51,126:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:19:53,416:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=5&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:19:54,124:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:20:00,791:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:20:01,506:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:20:08,230:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=7&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
root:ERROR:2022-10-06 16:20:08,787:can only concatenate str (not "NoneType") to str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\crawler.py", line 106, in next_page_bestbuy
    return "https://www.bestbuy.com" + next_page_link.get('href')
TypeError: can only concatenate str (not "NoneType") to str
urllib3.connectionpool:DEBUG:2022-10-06 16:20:09,565:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:20:11,002:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
root:ERROR:2022-10-06 16:20:19,374:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:20:19,965:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:20:32,155:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
root:ERROR:2022-10-06 16:20:51,610:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:20:52,431:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:20:53,835:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 21616
root:ERROR:2022-10-06 16:21:23,859:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:21:24,107:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:21:25,284:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 16:21:40,453:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:21:40,483:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:21:41,699:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 16:22:00,177:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:22:01,964:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:22:03,100:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 16:22:33,991:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:22:34,024:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:22:35,120:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 16:22:54,484:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
werkzeug:INFO:2022-10-06 16:29:43,718:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 16:29:43,718:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 16:29:50,010:127.0.0.1 - - [06/Oct/2022 16:29:50] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 16:29:50,016:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:29:51,632:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:29:52,377:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:29:53,560:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:29:54,268:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:29:55,866:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:29:56,327:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:29:57,699:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:29:58,204:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:10,883:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 34609
urllib3.connectionpool:DEBUG:2022-10-06 16:30:11,202:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:13,489:https://www.bestbuy.com:443 "GET /site/speakers/floor-speakers/abcat0205003.c?id=abcat0205003 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:30:14,139:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:16,506:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=2&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:30:17,189:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:19,486:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=3&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:30:20,196:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:22,352:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=4&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:30:23,085:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:31,056:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=5&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:30:31,764:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:34,389:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:30:35,061:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:40,632:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=7&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
root:ERROR:2022-10-06 16:30:41,164:can only concatenate str (not "NoneType") to str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\crawler.py", line 106, in next_page_bestbuy
    return "https://www.bestbuy.com" + next_page_link.get('href')
TypeError: can only concatenate str (not "NoneType") to str
urllib3.connectionpool:DEBUG:2022-10-06 16:30:41,692:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:30:42,841:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
root:ERROR:2022-10-06 16:31:02,494:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:31:02,990:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:31:04,195:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 24123
root:ERROR:2022-10-06 16:31:12,240:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:31:12,946:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:31:25,169:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 21616
root:ERROR:2022-10-06 16:31:55,774:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:31:55,999:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:31:57,123:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
root:ERROR:2022-10-06 16:32:05,465:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:32:05,499:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:32:06,632:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
root:ERROR:2022-10-06 16:32:27,057:cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\extractors\helpers.py", line 71, in get_details_from_newegg_and_store
    table.insert_one(results)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 621, in insert_one
    self._insert_one(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 562, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1448, in _retryable_write
    return self._retry_with_session(retryable, func, s, None)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1321, in _retry_with_session
    return self._retry_internal(retryable, func, session, bulk)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\_csot.py", line 105, in csot_wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\mongo_client.py", line 1362, in _retry_internal
    return func(session, sock_info, retryable)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\collection.py", line 550, in _insert_command
    result = sock_info.command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 794, in command
    self._raise_connection_failure(error)
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\pool.py", line 766, in command
    return command(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\network.py", line 127, in command
    request_id, msg, size, max_doc_size = message._op_msg(
  File "C:\Users\DELL\anaconda3\envs\Products_scraper\lib\site-packages\pymongo\message.py", line 687, in _op_msg
    return _op_msg_uncompressed(flags, command, identifier, docs, opts)
bson.errors.InvalidDocument: cannot encode object: <built-in function id>, of type: <class 'builtin_function_or_method'>
urllib3.connectionpool:DEBUG:2022-10-06 16:32:28,960:Starting new HTTPS connection (1): www.newegg.com:443
werkzeug:INFO:2022-10-06 16:35:45,745:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
werkzeug:INFO:2022-10-06 16:35:45,745:[33mPress CTRL+C to quit[0m
werkzeug:INFO:2022-10-06 16:36:26,442:127.0.0.1 - - [06/Oct/2022 16:36:26] "GET /begin_crawl HTTP/1.1" 200 -
urllib3.connectionpool:DEBUG:2022-10-06 16:36:26,452:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:36:27,950:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:36:28,751:Starting new HTTPS connection (1): www.amazon.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:36:41,209:https://www.amazon.com:443 "GET /s?i=electronics-intl-ship&bbn=16225009011&rh=n%3A667846011%2Cn%3A172563%2Cn%3A3236453011&dc&ds=v1%3AkKPTlIlAMSfbOpQLhDhvz4Hv1mlYpGT9OrTBQR9h6DI&qid=1664985358&rnid=172563&ref=sr_nr_n_4&page=2 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:36:41,762:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:36:43,483:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:36:44,047:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:36:45,429:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=1 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:36:46,004:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:36:50,333:https://www.newegg.com:443 "GET /p/pl?N=100008225%20600030002&page=2 HTTP/1.1" 200 34728
urllib3.connectionpool:DEBUG:2022-10-06 16:36:50,677:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:36:52,904:https://www.bestbuy.com:443 "GET /site/speakers/floor-speakers/abcat0205003.c?id=abcat0205003 HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:36:53,617:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:36:55,759:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=2&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:36:56,454:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:36:59,895:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=3&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:37:00,596:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:37:02,925:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=4&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:37:03,669:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:37:16,968:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=5&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:37:17,710:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:37:24,852:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 500 243363
urllib3.connectionpool:DEBUG:2022-10-06 16:37:25,653:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:37:27,537:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=6&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
urllib3.connectionpool:DEBUG:2022-10-06 16:37:28,232:Starting new HTTPS connection (1): www.bestbuy.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:37:29,984:https://www.bestbuy.com:443 "GET /site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0205003&cp=7&id=pcat17071&iht=n&ks=960&list=y&sc=Global&st=categoryid%24abcat0205003&type=page&usc=All%20Categories HTTP/1.1" 200 None
root:ERROR:2022-10-06 16:37:30,519:can only concatenate str (not "NoneType") to str
Traceback (most recent call last):
  File "C:\Users\DELL\Desktop\Python work\Products_scraper\crawler.py", line 106, in next_page_bestbuy
    return "https://www.bestbuy.com" + next_page_link.get('href')
TypeError: can only concatenate str (not "NoneType") to str
urllib3.connectionpool:DEBUG:2022-10-06 16:37:31,163:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:37:32,294:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
urllib3.connectionpool:DEBUG:2022-10-06 16:37:42,096:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:37:54,311:https://www.newegg.com:443 "GET /p/0S6-00SH-00143 HTTP/1.1" 200 23806
urllib3.connectionpool:DEBUG:2022-10-06 16:38:15,347:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:38:16,740:https://www.newegg.com:443 "GET /cerwin-vega-cwv-sl28/p/N82E16886716004 HTTP/1.1" 200 21616
urllib3.connectionpool:DEBUG:2022-10-06 16:38:26,153:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:38:27,369:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
urllib3.connectionpool:DEBUG:2022-10-06 16:38:50,706:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:38:52,105:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
urllib3.connectionpool:DEBUG:2022-10-06 16:39:21,787:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:39:22,936:https://www.newegg.com:443 "GET /p/0S6-000F-000F2 HTTP/1.1" 200 21766
urllib3.connectionpool:DEBUG:2022-10-06 16:39:43,171:Starting new HTTPS connection (1): www.newegg.com:443
urllib3.connectionpool:DEBUG:2022-10-06 16:39:44,371:https://www.newegg.com:443 "GET /p/0S6-000F-000F8 HTTP/1.1" 200 22648
